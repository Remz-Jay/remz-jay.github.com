<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: bacula | Rem.co: Remco Overdijk]]></title>
  <link href="https://rem.co/blog/categories/bacula/atom.xml" rel="self"/>
  <link href="https://rem.co/"/>
  <updated>2018-01-25T14:17:37+01:00</updated>
  <id>https://rem.co/</id>
  <author>
    <name><![CDATA[Remco Overdijk]]></name>
    <email><![CDATA[remco@rem.co]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Bacula: Cancelling all jobs that are currently writing]]></title>
    <link href="https://rem.co/blog/2015/02/09/bacula-cancelling-all-jobs-that-are-currently-writing/"/>
    <updated>2015-02-09T14:08:07+01:00</updated>
    <id>https://rem.co/blog/2015/02/09/bacula-cancelling-all-jobs-that-are-currently-writing</id>
    <content type="html"><![CDATA[<p><em>Just a quick post with the oneliner of the day.</em></p>

<p><strong>Scenario</strong>: after a bacula director restart a couple of jobs were stuck on the FD with message:</p>

<pre><code class="bash Bacula File Director Error">Running Jobs:
Writing: Incremental Backup job node.cluster.company.com JobId=8702 Volume=""
    pool="bacula.director.company.com:pool:default.incremental" device="DefaultFileStorage" (/mnt/bacula/default)
    spooling=0 despooling=0 despool_wait=0
    Files=0 Bytes=0 AveBytes/sec=0 LastBytes/sec=0
FDSocket closed
</code></pre>

<!-- more -->


<p>There were a couple of these jobs that were stuck, preventing all other jobs from running, because those were waiting for a free slot on the FD.</p>

<p><strong>Solution?</strong> Well, I <em>could</em> have resumed or fixed those jobs, but I&rsquo;m in a hurry, so I just cancelled them so the rest of the schedule could be processed. And I&rsquo;m lazy too, so I just cancelled all currently writing jobs in one go:</p>

<pre><code class="bash Bacula Oneliner: Cancel all currently writing jobs">for j in `echo "s storage" | bconsole | grep -i writing | awk '{print $6}'`; do echo "cancel $j" | bconsole; done
</code></pre>

<p>After that, the schedule started processing right away. Next issue.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bacula: Purging and deleting old volumes]]></title>
    <link href="https://rem.co/blog/2015/01/15/bacula-purging-and-deleting-old-volumes/"/>
    <updated>2015-01-15T14:08:02+01:00</updated>
    <id>https://rem.co/blog/2015/01/15/bacula-purging-and-deleting-old-volumes</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been using bacula for a couple of months now in conjunction with puppet to
make automated backups of all servers that are managed by puppet.
My bacula setup labels a volume for every job it runs with a unique name:</p>

<pre><code class="ini Bacula Label Format">Label Format = "${Job}.${Year}${Month:p/2/0/r}${Day:p/2/0/r}.${Hour:p/2/0/r}${Minute:p/2/0/r}"
</code></pre>

<p>These volumes are automatically purged once the retention of all files contained on the volume expires (which is
        configured per-pool). Due to the unique names however, the volumes cannot
be recycled. The result of this is that the volumes that have been marked as
purged in the catalog remain as-is on the disk. After some time this ultimately
resulted in a full disk, thus halting all backups performed on that pool. Not
good. Not good at all.</p>

<!-- more -->


<p>I thought volumes would be truncated at the time they are marked as purged, but
I probably made some configuration error somewhere along the road or I don&rsquo;t
quite understand how the truncating process works, because all of my purged
disks are using their original disk space.</p>

<p>Because I&rsquo;m pressed for time and can&rsquo;t be bothered with old backups anyway,
                I&rsquo;ve decided to just delete all purged volumes (which were beyond their
                        retention date anyway). Perhaps the steps I took to delete these
                volumes can help others (Or others can recommend me a better way to
                        deal with old volumes), so here goes:</p>

<h2>Pruning all clients</h2>

<p>Before you start cleaning old volumes, it might be wise to ensure that all
volumes are pruned before cleaning, so you maximize the number of volumes you
are going to delete.</p>

<pre><code class="bash Pruning all clients">#!/bin/bash
clients=`mysql -e'select Name from Client ORDER BY Name ASC;' bacula | tail -n+2`

for client in `echo $clients`
do
  echo "prune files client=${client} yes" | bconsole
done
</code></pre>

<h2>Checking the number of volumes to be purged</h2>

<p>Using <code>list volumes</code> in <code>bconsole</code> you can check the status of all volumes known to bacula.
I&rsquo;m merely interested in the number of volumes that are currently marked as purged:</p>

<pre><code class="bash Listing the number of Purged Volumes">echo "list volumes" | bconsole | grep "Purged" | awk {'print $4'} | wc -l
</code></pre>

<p>This resulted in a list of <em>thousands</em> of volumes. (We&rsquo;re running, full, incremental and diff backups, so the numbers stack up). Time to get rid of them.</p>

<h2>Removing purged volumes from the catalog and deleting them</h2>

<p>Using this script I&rsquo;ve removed all purged volumes from the catalog, after which they were physically deleted from the disk, freeing up precious space for more recent backups.
<figure class='code'><figcaption><span>Deleting all Purged Volumes</p></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>&lt;h1&gt;!/bin/bash&lt;/h1&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;for f in &lt;code&gt;echo <span class="s2">&quot;list volume&quot;</span> <span class="p">|</span> bconsole <span class="p">|</span> grep Purged <span class="p">|</span> cut -d <span class="s1">&#39; &#39;</span> -f6&lt;/code&gt;<span class="p">;</span> <span class="k">do</span>
</span><span class='line'>    <span class="nb">echo</span> <span class="p">&amp;</span>ldquo<span class="p">;</span>delete <span class="nv">volume</span><span class="o">=</span><span class="nv">$f</span> yes<span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">|</span> bconsole<span class="p">;</span>
</span><span class='line'>    rm -rf /mnt/bacula/default/<span class="nv">$f</span><span class="p">;</span>
</span><span class='line'><span class="k">done</span>
</span></code></pre></td></tr></table></div></figure></p>

<h2>Removing volumes that are missing from the catalog</h2>

<p>Somehow I also ended up with some volumes on the disk that were not present in the bacula catalog at all. In my opinion these could be cleaned up as well, hence:</p>

<pre><code class="bash Deleting volumes that are not present in the catalog">#!/bin/bash

cd /mnt/bacula/default
for i in `find . -maxdepth 1 -type f -printf "%f\n"`; do
  echo "list volume=$i" | bconsole | if grep --quiet "No results to list"; then
        echo "$i is ready to be deleted"
        rm -f /mnt/bacula/default/$i
  fi
done
</code></pre>

<h2>Finishing up</h2>

<p>To prevent full disks these tasks should be scheduled using <code>cron</code> and run daily (or at least weekly) to keep your disks and catalog lean &amp; clean.</p>
]]></content>
  </entry>
  
</feed>
